# 100-days-of-compression
Starting April 2nd, I commit to spending minimum half an hour every day for the next 100 days learning about compression. This journey is driven by my fascination with the intersection of compression and intelligence, inspired by a quote from Marcus Hutter:

"Being able to compress well is closely related to intelligence as explained below. While intelligence is a slippery concept, file sizes are hard numbers. Wikipedia is an extensive snapshot of Human Knowledge. If you can compress the first 1GB of Wikipedia better than your predecessors, your (de)compressor likely has to be smart(er)"

## Basic Algorithms
- [x] Run-length Encoding(RLE)

## Python Modules
Adapted from : https://docs.python.org/3/library/archiving.html
- [x] zlib 
- [ ] gzip 
- [ ] bz2
- [ ] lzma
- [ ] zipfile
- [ ] tarfile

# Matt Mahoney Data Compression Explained

- [ ] Information theory
 - [ ]   Compression as Artificial Intelligence Problem

## Mathematics Preliminaries from Data Compression by Khalid Sayood
- [ ] Introductory Information Theory
- [ ] Models
  - [ ] Physical Models
  - [ ] Physical Models
  - [ ] Markov Models
  - [ ] Composite Source Model
- [ ] Coding
  - [ ] Uniquely Decodable Codes
  - [ ] Prefix Codes
  - [ ] The Kraft-McMilllan Inequality
- [ ] Algorithmic Information theory


# Coding techniques

- [x] Huffman Coding
- [ ] Arithmetic Coding
- [ ] Asymmetric Binary Coding
- [ ] Numeric Codes

# Transforms

- [ ] LZ77 and Variants
  - [ ] LZSS
  - [ ] Deflate
  - [ ] LZMA
  - [ ]  LZX
  - [ ]  ROLZ
  - [ ]  LZP
  - [ ]  Snappy
  - [ ]  Deduplication

  
